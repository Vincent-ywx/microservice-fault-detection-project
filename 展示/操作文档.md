



## sock-shop微服务部署

**命令行进入D:\microservice-fault-detection-project\demo\microservices-demo>文件目录**

```
cd D:\microservice-fault-detection-project\demo\microservices-demo
```



- 查看状态

```Bash
minikube status
```

- 启动微服务sock-shop

```
minikube start --driver=docker
```

- 查看该项目的所有微服务（具体结构查看sock-shop文档）

```kubectl get svc -n sock-shopBash
kubectl get svc -n sock-shop
```

- 启动集群中的pod


```
kubectl get pods -n sock-shop
```

你可以使用下面的命令给所有 `Deployment` 做一个滚动重启：

```
kubectl rollout restart deployment -n sock-shop
```

效果如图：

![image-20250603211245875](C:\Users\adminer\AppData\Roaming\Typora\typora-user-images\image-20250603211245875.png)

## 🧩 SockShop 各 Pod 解释（Explanation of SockShop Pods）

| Pod 名称       | 功能描述（中文）                                  | Function Description (English)                               |
| -------------- | ------------------------------------------------- | ------------------------------------------------------------ |
| `front-end`    | 用户界面服务，提供 Web 应用界面，调用后端其他服务 | The web UI service. It serves the user-facing website and communicates with other services. |
| `carts`        | 购物车服务，处理添加、删除商品等操作              | Manages the shopping cart — add/remove items, retrieve cart contents |
| `carts-db`     | carts 服务使用的 MongoDB 数据库                   | MongoDB backing the carts service                            |
| `catalogue`    | 商品目录服务，提供所有商品数据                    | Provides product listings, descriptions, prices, and stock info |
| `catalogue-db` | catalogue 使用的 MongoDB 数据库                   | MongoDB for the catalogue service                            |
| `orders`       | 订单服务，处理下单请求                            | Handles order placement and processing                       |
| `orders-db`    | orders 服务使用的 MySQL 数据库                    | MySQL used to persist orders                                 |
| `payment`      | 支付服务，模拟支付流程（总是支付成功）            | Simulates a payment process (always succeeds)                |
| `queue-master` | 用于处理异步任务的服务（如发送邮件）              | Consumes tasks from RabbitMQ queue, e.g., sending confirmation emails |
| `rabbitmq`     | 消息队列系统，用于服务间异步通信                  | Message broker used for decoupling services (mainly orders + email tasks) |
| `session-db`   | 用户 session 存储服务（Redis）                    | Redis service for storing user sessions (key-value store)    |
| `shipping`     | 发货服务，模拟发货操作                            | Simulates shipping of orders                                 |
| `user`         | 用户账户服务，处理注册、登录等功能                | Manages user registration and authentication                 |
| `user-db`      | user 服务使用的 MySQL 数据库                      | MySQL database backing the user service                      |



------

## 🧠 微服务调用关系简图（Call Graph Overview）

```
sql复制编辑+-------------+
|  front-end  |
+------+------+---------------+------------------+
       |                      |                  |
   [carts]                [user]            [catalogue]
       |                      |                  |
  [carts-db]            [user-db]         [catalogue-db]
       |
   [orders]---[payment]---[shipping]
       |
   [orders-db]
       |
  [queue-master] <--> [rabbitmq]
```

> `front-end` 是唯一直接面向用户的服务，其它服务都是后台支撑。

------

## 总结：

SockShop 是一个典型的电商微服务架构示例，模块划分清晰：

- 包括用户管理、商品、购物车、订单、支付、发货、异步处理等核心电商模块。
- 每个服务职责单一，使用独立容器部署，具备良好的“微服务自治性”。

- 运行以下命令，启动 front-end，打开浏览器

```Bash
minikube service front-end -n  sock-shop
```





## chaosmesh注入

- ChaosMesh 提供了 Web UI，可以查看实验的执行情况：

```Plain
kubectl port-forward -n chaos-testing svc/chaos-dashboard 2333:2333
```

然后通过浏览器访问 http://localhost:2333 查看结果。

```

```

- 获取令牌

运行如下命令：

```
cd D:\microservice-fault-detection-project\chaosmesh\token
```

```
kubectl apply -f rbac.yaml
```

```
kubectl create token account-cluster-manager-hrgfu
```

```
account-cluster-manager-hrgfu
```





## prometheus查看数据

输入以下指令，查看监控服务

```Bash
kubectl get svc -n monitoring
```

输入下面两个命令，分别得到他们的IP地址

```Bash
minikube service prometheus -n monitoring --url
minikube service grafana -n monitoring --url


monitoring无法查看个服务的HTTP 层指标
```



## monitoring无法查看个服务的HTTP 层指标，采用Istio

------



## 为 SockShop 集成 Istio + Prometheus（支持 AutoMAP）

为了支持 AutoMAP 的行为图构建和根因定位，需要采集以下 HTTP 层指标：

- 请求延迟（Mlat）
- 吞吐率（Mthr）
- HTTP 状态码统计（用于 Mavl）

最简单可靠的方式是使用 **Istio + Prometheus** 实现自动采集。

#### 🔹 步骤 1：安装 Istio（示例为 Minikube 环境）

```
https://istio.io/downloadIstio | ISTIO_VERSION=1.22.0 sh -
cd istio-1.22.0
export PATH=$PWD/bin:$PATH
istioctl install --set profile=demo -y
```

#### 🔹 步骤 2：启用自动注入 sidecar

```
kubectl label namespace sock-shop istio-injection=enabled
```

#### 🔹 步骤 3：重新部署 SockShop（确保注入 sidecar）

```
kubectl delete -f complete-demo.yaml -n sock-shop
kubectl apply -f complete-demo.yaml -n sock-shop
```

> 所有服务会自动注入 `istio-proxy` 容器，用于转发流量并采集请求指标。

#### 🔹 步骤 4：访问 Istio 自带的 Prometheus

Istio 自带 Prometheus，可用于直接查询：

```
kubectl port-forward svc/prometheus -n istio-system 9090:9090
```

浏览器打开：

[Prometheus Time Series Collection and Processing Server](http://localhost:9090/graph?g0.expr=&g0.tab=1&g0.display_mode=lines&g0.show_exemplars=0&g0.range_input=1h)

> ```
> http://localhost:9090
> ```
>



验证所有微服务是否已成功注入 sidecar

```
kubectl get pods -n sock-shop -o jsonpath="{range .items[*]}{.metadata.name}{'\t'}{range .spec.containers[*]}{.name}{','}{end}{'\n'}{end}" | sort
```



| 指标              | PromQL 示例                                                  |
| ----------------- | ------------------------------------------------------------ |
| **Mlat** 平均延迟 | `rate(istio_request_duration_milliseconds_sum[1m]) / rate(istio_request_duration_milliseconds_count[1m])` |
| **Mthr** 吞吐率   | `rate(istio_requests_total[1m])`                             |
| **Mcon** 并发数   | `rate(istio_requests_total[1m]) / (rate(istio_request_duration_milliseconds_sum[1m]) / rate(istio_request_duration_milliseconds_count[1m]))` |
| **Mavl** 可用率   | `sum(rate(istio_requests_total{response_code=~"2.."}[1m])) / sum(rate(istio_requests_total[1m]))` |

![image-20250607230128311](C:\Users\adminer\AppData\Roaming\Typora\typora-user-images\image-20250607230128311.png)

### **触发正常负载**

AutoMAP 依赖“稳定运行状态”的行为图（normal graph），你需要确保 SockShop 系统先处于一段时间的正常运行。

## 使用 Selenium/JMeter 等工具批量发送请求。

打开jmeter，测试front-end

## 使用 ChaosMesh front-end微服务注入延迟或故障

行以下命令检查 ChaosMesh 是否已就绪：

```
kubectl get pods -n chaos-testing
```

## 完整的 AutoMAP 原型脚本框架

- 数据采集阶段

- 图建模阶段

- 根因定位阶段（相似度 + 启发式随机游走）

  

## 用途如下：

### ① **根因定位：定位出最可能出问题的微服务**

输出的排序如下：

```
1. payment（得分: 0.1890）
2. catalogue（得分: 0.1851）
3. user（得分: 0.1724）
...
```

这表示，在某一时刻系统表现异常时，`payment` 服务最可能是“根因故障点”。这可以帮助你：

- **加快排查故障速度**：无需从几十个服务中盲查；
- **优先重启或降级有问题的服务**；
- **与 ChaosMesh 的注入点做比对**，验证诊断精度；
- **作为运维自动化策略的一部分（如告警路由、SLO 监控）**。

------

### ② **行为图构建与节点 Profile 数据**

你看到的 `front-end profile: [...]` 是该服务的特征向量，由多个指标拼接而成：

- 包括 **Mlat（延迟）**、**Mcpu（CPU）**、**Mmem（内存）**、**Mthr（请求吞吐）** 等多维度；
- 是行为图中每个节点的**语义嵌入**，用于后续的**相似度匹配**；
- 可用于可视化分析，或者作为输入特征用于机器学习。

------

### ③ **构建行为图后可以进一步用于：**

| 功能           | 说明                                                         |
| -------------- | ------------------------------------------------------------ |
| 异常传播分析   | 行为图中的边表示调用依赖，可以分析异常是如何“传染”的         |
| 多时间段对比   | 多轮运行后对比 profile 向量变化趋势，发现服务劣化趋势        |
| 可视化展示     | 将图导出为 `.dot` 或使用 `networkx`+`matplotlib` 可视化服务间依赖 |
| 模拟或回归测试 | 在模拟故障时检查 AutoMAP 是否能准确预测根因                  |

```
import numpy as np
import networkx as nx
import datetime
from prometheus_api_client import PrometheusConnect
from scipy.stats import chi2_contingency
from sklearn.metrics.pairwise import cosine_similarity
import warnings

warnings.filterwarnings("ignore")

PROMETHEUS_URL = "http://localhost:9090"
prom = PrometheusConnect(url=PROMETHEUS_URL, disable_ssl=True)

SERVICES = [
    "front-end", "carts", "orders", "user", "payment", "shipping", "catalogue"
]

METRICS = ["Mlat", "Mthr", "Mcon", "Mcpu", "Mio", "Mmem", "Mavl"]

METRIC_QUERIES = {
    "Mlat": 'rate(istio_request_duration_milliseconds_sum{{destination_service_name="{svc}"}}[1m]) / rate(istio_request_duration_milliseconds_count{{destination_service_name="{svc}"}}[1m])',
    "Mthr": 'rate(istio_requests_total{{destination_service_name="{svc}"}}[1m])',
    "Mcon": 'rate(istio_requests_total{{destination_service_name="{svc}"}}[1m]) / (rate(istio_request_duration_milliseconds_sum{{destination_service_name="{svc}"}}[1m]) / rate(istio_request_duration_milliseconds_count{{destination_service_name="{svc}"}}[1m]))',
    "Mavl": 'sum(rate(istio_requests_total{{destination_service_name="{svc}", response_code=~"2.."}}[1m])) / sum(rate(istio_requests_total{{destination_service_name="{svc}"}}[1m]))',
    "Mcpu": 'rate(container_cpu_usage_seconds_total{{pod=~"{svc}.*"}}[1m])',
    "Mio": 'rate(container_fs_reads_bytes_total{{pod=~"{svc}.*"}}[1m]) + rate(container_fs_writes_bytes_total{{pod=~"{svc}.*"}}[1m])',
    "Mmem": 'container_memory_usage_bytes{{pod=~"{svc}.*"}}'
}

END_TIME = datetime.datetime.utcnow()
START_TIME = END_TIME - datetime.timedelta(minutes=5)
STEP = "15s"

def conditional_independence_test(x, y):
    contingency_table = np.histogram2d(x, y, bins=10)[0]
    if np.any(contingency_table == 0):
        return False
    chi2, p_value, _, _ = chi2_contingency(contingency_table)
    return p_value > 0.05

def fetch_metrics(prom, metric_type, services):
    data = {}
    fixed_length = 20
    for svc in services:
        print(f"获取指标: {metric_type} @ {svc}")
        query = METRIC_QUERIES[metric_type].format(svc=svc)
        try:
            result = prom.custom_query_range(
                query=query,
                start_time=START_TIME,
                end_time=END_TIME,
                step=STEP
            )
            svc_data = []
            for ts in result:
                values = [float(val[1]) for val in ts["values"] if val[1] != "NaN"]
                svc_data.extend(values)
            if len(svc_data) < fixed_length:
                svc_data.extend([0] * (fixed_length - len(svc_data)))
            else:
                svc_data = svc_data[:fixed_length]
            data[svc] = np.array(svc_data)
        except Exception as e:
            print(f"[错误] Prometheus 查询失败: {e}")
            data[svc] = np.zeros(fixed_length)
    return data

def get_all_metrics(prom):
    metrics_dict = {}
    for metric in METRICS:
        metrics_dict[metric] = fetch_metrics(prom, metric, SERVICES)
    return metrics_dict

def build_behavior_graph(metrics_dict):
    G = nx.Graph()
    for idx, svc in enumerate(SERVICES):
        G.add_node(idx, name=svc)
    for i in range(len(SERVICES)):
        for j in range(i + 1, len(SERVICES)):
            connected = False
            for metric in METRICS:
                data = metrics_dict[metric]
                indep = conditional_independence_test(data[SERVICES[i]], data[SERVICES[j]])
                if not indep:
                    connected = True
                    break
            if connected:
                G.add_edge(i, j)
    return G

def compute_profiles(metrics_dict):
    profiles = {}
    fixed_length = 20
    for idx, svc in enumerate(SERVICES):
        profile = []
        for metric in METRICS:
            vec = metrics_dict[metric].get(svc, np.zeros(fixed_length))
            if len(vec) < fixed_length:
                vec = np.pad(vec, (0, fixed_length - len(vec)), 'constant')
            elif len(vec) > fixed_length:
                vec = vec[:fixed_length]
            profile.extend(vec)
        profiles[idx] = np.array(profile)
    return profiles

def compute_similarity_matrix(profiles):
    mat = np.array(list(profiles.values()))
    sim = cosine_similarity(mat)
    return sim

def random_walk_ranking(G, scores, restart_prob=0.7, max_iter=100):
    nodes = list(G.nodes)
    A = nx.adjacency_matrix(G).astype(float)
    A = A.todense()
    n = len(nodes)
    A = A / A.sum(axis=1, keepdims=True)
    p = np.ones((n, 1)) / n
    r = scores.reshape((n, 1))

    for _ in range(max_iter):
        p = (1 - restart_prob) * A @ p + restart_prob * r

    ranking = {nodes[i]: p[i, 0] for i in range(n)}
    return sorted(ranking.items(), key=lambda x: x[1], reverse=True)

if __name__ == "__main__":
    metrics_dict = get_all_metrics(prom)
    G = build_behavior_graph(metrics_dict)
    print(f"\n 行为图节点数: {G.number_of_nodes()}")
    print(f" 行为图边数: {G.number_of_edges()}")

    profiles = compute_profiles(metrics_dict)
    frontend_id = SERVICES.index("front-end")
    print(f"\n front-end profile 长度: {len(profiles[frontend_id])}")

    sim_matrix = compute_similarity_matrix(profiles)
    anomaly_score = np.array([np.linalg.norm(profiles[i] - profiles[frontend_id]) for i in range(len(SERVICES))])
    anomaly_score = anomaly_score / np.sum(anomaly_score)

    ranking = random_walk_ranking(G, anomaly_score)
    print("\n 根因服务排名：")
    for rank, (svc_idx, score) in enumerate(ranking):
        print(f"{rank + 1}. {SERVICES[svc_idx]}（得分: {score:.4f}）")

```

